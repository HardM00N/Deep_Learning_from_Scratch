{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"밑바닥부터 시작하는 딥러닝 5장.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1NtYaiTROrwak8SRlq8hKcLKQ2Hg0p8Jq","authorship_tag":"ABX9TyMj1AhPlcgLY9bj1Km8r0x/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"YrwlvxNHT3-C","executionInfo":{"status":"ok","timestamp":1658045140686,"user_tz":-540,"elapsed":360,"user":{"displayName":"배재현","userId":"16111717144670092065"}}},"outputs":[],"source":["# 곱셈 계층 구현하기\n","\n","class MulLayer:\n","    def __init__(self):\n","        self.x = None\n","        self.y = None\n","\n","    def forward(self, x, y):\n","        self.x = x\n","        self.y = y\n","        out = x * y\n","\n","        return out\n","    \n","    def backward(self, dout):\n","        dx = dout * self.y  # x와 y를 바꾼다.\n","        dy = dout * self.x\n","\n","        return dx, dy"]},{"cell_type":"code","source":["apple = 100\n","apple_num = 2\n","tax = 1.1\n","\n","# 계층들\n","mul_apple_layer = MulLayer()\n","mul_tax_layer = MulLayer()\n","\n","# 순전파\n","apple_price = mul_apple_layer.forward(apple, apple_num)\n","price = mul_tax_layer.forward(apple_price, tax)\n","\n","print(price)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hPNIpcr0IBod","executionInfo":{"status":"ok","timestamp":1658045141072,"user_tz":-540,"elapsed":11,"user":{"displayName":"배재현","userId":"16111717144670092065"}},"outputId":"b6a6a22d-894f-4b77-f199-488f901233d1"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["220.00000000000003\n"]}]},{"cell_type":"code","source":["# 역전파\n","dprice = 1\n","dapple_price, dtax = mul_tax_layer.backward(dprice)\n","dapple, dapple_num = mul_apple_layer.backward(dapple_price)\n","\n","print(dapple, dapple_num, dtax)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UNvRufsEIcky","executionInfo":{"status":"ok","timestamp":1658045141073,"user_tz":-540,"elapsed":10,"user":{"displayName":"배재현","userId":"16111717144670092065"}},"outputId":"10c61f54-7046-4cc4-d354-60a4749faa72"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["2.2 110.00000000000001 200\n"]}]},{"cell_type":"code","source":["# 덧셈 계층 구현하기\n","\n","class AddLayer:\n","    def __init__(self):\n","        pass\n","\n","    def forward(self, x, y):\n","        out = x + y\n","        return out\n","\n","    def backward(self, dout):\n","        dx = dout * 1\n","        dy = dout * 1\n","\n","        return dx, dy"],"metadata":{"id":"0_gtdJdOJBKb","executionInfo":{"status":"ok","timestamp":1658045141073,"user_tz":-540,"elapsed":8,"user":{"displayName":"배재현","userId":"16111717144670092065"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["apple = 100\n","apple_num = 2\n","orange = 150\n","orange_num = 3\n","tax = 1.1\n","\n","# 계층들\n","mul_apple_layer = MulLayer()\n","mul_orange_layer = MulLayer()\n","add_apple_orange_layer = AddLayer()\n","mul_tax_layer = MulLayer()\n","\n","# 순전파\n","apple_price = mul_apple_layer.forward(apple, apple_num) # (1)\n","orange_price = mul_orange_layer.forward(orange, orange_num) # (2)\n","all_price = add_apple_orange_layer.forward(apple_price, orange_price)   # (3)\n","price = mul_tax_layer.forward(all_price, tax)   # (4)\n","\n","# 역전파\n","dprice = 1\n","dall_price, dtax = mul_tax_layer.backward(dprice)   # (4)\n","dapple_price, dorange_price = add_apple_orange_layer.backward(dall_price)   # (3)\n","dorange, dorange_num = mul_orange_layer.backward(dorange_price) # (2)\n","dapple, dapple_num = mul_apple_layer.backward(dapple_price) # (1)\n","\n","print(price)    # 715\n","print(dapple_num, dapple, dorange, dorange_num, dtax)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_m8Dc23CJnhw","executionInfo":{"status":"ok","timestamp":1658045141073,"user_tz":-540,"elapsed":7,"user":{"displayName":"배재현","userId":"16111717144670092065"}},"outputId":"a1a7e1dd-5145-4960-e03c-082b40e5a16b"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["715.0000000000001\n","110.00000000000001 2.2 3.3000000000000003 165.0 650\n"]}]},{"cell_type":"code","source":["# ReLU 계층 구현하기\n","\n","class Relu: \n","    def __init__(self):\n","        self.mask = None\n","\n","    def forward(self, x):\n","        self.mask = (x <= 0)\n","        out = x.copy()\n","        out[self.mask] = 0\n","\n","        return out\n","\n","    def backward(self, dout):\n","        dout[self.mask] = 0\n","        dx = dout\n","\n","        return dx"],"metadata":{"id":"wJOINXUlM3O8","executionInfo":{"status":"ok","timestamp":1658045141074,"user_tz":-540,"elapsed":7,"user":{"displayName":"배재현","userId":"16111717144670092065"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","\n","x = np.array([[1.0, -0.5], [-2.0, 3.0]])\n","print(x)\n","\n","mask = (x <= 0)\n","print(mask)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gEG5TnL0NqZE","executionInfo":{"status":"ok","timestamp":1658045141074,"user_tz":-540,"elapsed":7,"user":{"displayName":"배재현","userId":"16111717144670092065"}},"outputId":"2ded0995-1e69-476e-9123-f99f04100058"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["[[ 1.  -0.5]\n"," [-2.   3. ]]\n","[[False  True]\n"," [ True False]]\n"]}]},{"cell_type":"code","source":["# Sigmoid 계층 구현하기\n","\n","class Sigmoid:\n","    def __init__(self):\n","        self.out = None\n","    \n","    def forward(self, x):\n","        out = 1 / (1 + np.exp(-x))\n","        self.out = out\n","\n","        return out\n","    \n","    def backward(self, dout):\n","        dx = dout * (1.0 - self.out) * self.out\n","        \n","        return dx"],"metadata":{"id":"QrBJxwdDPrjd","executionInfo":{"status":"ok","timestamp":1658045141074,"user_tz":-540,"elapsed":5,"user":{"displayName":"배재현","userId":"16111717144670092065"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# 신경망의 순전파에서는 가중치 신호의 총합을 계산하기 때문에 행렬의 곱을 사용했음. \n","# 넘파이에서는 np.dot()\n","\n","X = np.random.rand(2)       # 입력\n","W = np.random.rand(2, 3)    # 가중치\n","B = np.random.rand(3)       # 편향\n","\n","print(X.shape) # (2,)\n","print(W.shape) # (2, 3)\n","print(B.shape) # (3, )\n","\n","Y = np.dot(X, W) + B\n","print(Y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FB8p6SOsQd46","executionInfo":{"status":"ok","timestamp":1658045141461,"user_tz":-540,"elapsed":392,"user":{"displayName":"배재현","userId":"16111717144670092065"}},"outputId":"da036320-f429-4128-a66e-3c12ab4d0057"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["(2,)\n","(2, 3)\n","(3,)\n","[0.60940263 1.54328696 0.80720541]\n"]}]},{"cell_type":"code","source":["# 순전파의 편향 덧셈\n","\n","X_dot_W = np.array([[0, 0, 0], [10, 10, 10]])\n","B = np.array([1, 2, 3])\n","\n","print(X_dot_W)\n","print(X_dot_W + B)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6aGkmFBjptDW","executionInfo":{"status":"ok","timestamp":1658045141462,"user_tz":-540,"elapsed":7,"user":{"displayName":"배재현","userId":"16111717144670092065"}},"outputId":"2aefa7d4-c689-41ec-f943-96b7d7cd282e"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["[[ 0  0  0]\n"," [10 10 10]]\n","[[ 1  2  3]\n"," [11 12 13]]\n"]}]},{"cell_type":"code","source":["# 편향의 역전파\n","\n","dY = np.array([[1, 2, 3], [4, 5, 6]])\n","print(dY)\n","\n","dB = np.sum(dY, axis=0)\n","print(dB)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XIPLaYj8qKz_","executionInfo":{"status":"ok","timestamp":1658045141462,"user_tz":-540,"elapsed":6,"user":{"displayName":"배재현","userId":"16111717144670092065"}},"outputId":"ad1b4d4b-daaa-401b-8068-c82f9d165dac"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["[[1 2 3]\n"," [4 5 6]]\n","[5 7 9]\n"]}]},{"cell_type":"code","source":["# 배치용 Affine 계층 구현하기\n","\n","class Affine:\n","    def __init__(self, W, b):\n","        self.W = W\n","        self.b = b\n","        self.x = None\n","        self.dW = None\n","        self.db = None\n","\n","    def forward(self, x):\n","        self.x = x\n","        out = np.dot(x, self.W) + self.b\n","\n","        return out\n","\n","    def backward(self, dout):\n","        dx = np.dot(dout, self.W.T)\n","        self.dW = np.dot(self.x.T, dout)\n","        self.db = np.sum(dout, axis=0)\n","\n","        return dx"],"metadata":{"id":"X_RaBEgorVr6","executionInfo":{"status":"ok","timestamp":1658045141462,"user_tz":-540,"elapsed":4,"user":{"displayName":"배재현","userId":"16111717144670092065"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["# Softmax-with-Loss 계층 구현하기\n","\n","class SoftmaxWithLoss:\n","    def __init__(self):\n","        self.loss = None    # 손실\n","        self.y = None       # softmax의 출력\n","        self.t = None       # 정답 레이블 (원-핫 벡터)\n","\n","    def forward(self, x, t):\n","        self.t = t\n","        self.y = softmax(x)\n","        self.loss = cross_entropy_error(self.y, self.t)\n","        return self.loss\n","\n","    def backward(self, dout=1):\n","        batch_size = self.t.shape[0]\n","        dx = (self.y - self.t) / batch_size\n","\n","        return dx"],"metadata":{"id":"fpTJZTmR_naP","executionInfo":{"status":"ok","timestamp":1658045141463,"user_tz":-540,"elapsed":5,"user":{"displayName":"배재현","userId":"16111717144670092065"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["# 오차역전파법을 적용한 신경망 구현하기\n","\n","%cd /content/drive/MyDrive/밑바닥부터 시작하는 딥러닝/ch05/\n","\n","import sys, os\n","sys.path.append(os.pardir)\n","import numpy as np\n","\n","from common.layers import *\n","from common.functions import softmax, cross_entropy_error\n","from common.gradient import numerical_gradient\n","from collections import OrderedDict\n","\n","class TwoLayerNet:\n","\n","    def __init__(self, input_size, hidden_size, output_size, weight_init_std=0.01):\n","\n","        # 가중치 초기화\n","        self.params = {}\n","        self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_size)\n","        self.params['b1'] = np.zeros(hidden_size)\n","        self.params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size)\n","        self.params['b2'] = np.zeros(output_size)\n","\n","        # 계층 생성\n","        self.layers = OrderedDict()\n","        self.layers['Affine1'] = Affine(self.params['W1'], self.params['b1'])\n","        self.layers['Relu1'] = Relu()\n","        self.layers['Affine2'] = Affine(self.params['W2'], self.params['b2'])\n","\n","        self.lastlayer = SoftmaxWithLoss()\n","\n","    def predict(self, x):\n","        for layer in self.layers.values():\n","            x = layer.forward(x)\n","\n","        return x\n","\n","    # x : 입력 데이터, t : 정답 레이블\n","    def loss(self, x, t):\n","        y = self.predict(x)\n","        return self.lastlayer.forward(y, t)\n","\n","    def accuracy(self, x, t):\n","        y = self.predict(x)\n","        y = np.argmax(y, axis=1)\n","        if t.ndim != 1 : t = np.argmax(t, axis=1)\n","\n","        accuracy = np.sum(y == t) / float(x.shape[0])\n","\n","        return accuracy\n","\n","    def numerical_gradient(self, x, t):\n","        loss_W = lambda W: self.loss(x, t)\n","\n","        grads = {}\n","        grads['W1'] = numerical_gradient(loss_W, self.params['W1'])\n","        grads['b1'] = numerical_gradient(loss_W, self.params['b1'])\n","        grads['W2'] = numerical_gradient(loss_W, self.params['W2'])\n","        grads['b2'] = numerical_gradient(loss_W, self.params['b2'])\n","\n","        return grads\n","\n","    def gradient(self, x, t):\n","        # 순전파\n","        self.loss(x, t)\n","\n","        # 역전파\n","        dout = 1\n","        dout = self.lastlayer.backward(dout)\n","\n","        layers = list(self.layers.values())\n","        layers.reverse()\n","        for layer in layers:\n","            dout = layer.backward(dout)\n","\n","        # 결과 저장\n","        grads = {}\n","        grads['W1'] = self.layers['Affine1'].dW\n","        grads['b1'] = self.layers['Affine1'].db\n","        grads['W2'] = self.layers['Affine2'].dW\n","        grads['b2'] = self.layers['Affine2'].db\n","\n","        return grads"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5RjAAdIhEhit","executionInfo":{"status":"ok","timestamp":1658045144797,"user_tz":-540,"elapsed":3339,"user":{"displayName":"배재현","userId":"16111717144670092065"}},"outputId":"9a38d13f-0d68-4113-af8a-f5645571fccd"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/밑바닥부터 시작하는 딥러닝/ch05\n"]}]},{"cell_type":"code","source":["# 오차역전파법으로 구한 기울기 검증하기\n","\n","%cd /content/drive/MyDrive/밑바닥부터 시작하는 딥러닝/ch05/\n","\n","import sys, os\n","sys.path.append(os.pardir)\n","import numpy as np\n","from dataset.mnist import load_mnist\n","from two_layer_net import TwoLayerNet\n","\n","# 데이터 읽기\n","(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n","\n","network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n","\n","x_batch = x_train[:3]\n","t_batch = t_train[:3]\n","\n","grad_numerical = network.numerical_gradient(x_batch, t_batch)\n","grad_backprop = network.gradient(x_batch, t_batch)\n","\n","# 각 가중치의 차이의 절댓값을 구한 후, 그 절댓값들의 평균을 낸다. \n","for key in grad_numerical.keys():\n","    diff = np.average(np.abs(grad_backprop[key] - grad_numerical[key]))\n","    print(key + \":\" + str(diff))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pV4U3jkvKvh7","executionInfo":{"status":"ok","timestamp":1658045156148,"user_tz":-540,"elapsed":11354,"user":{"displayName":"배재현","userId":"16111717144670092065"}},"outputId":"3abc0e90-6f00-4a51-e76e-04852efa4f28"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/밑바닥부터 시작하는 딥러닝/ch05\n","W1:3.524251025707778e-10\n","b1:2.0016671507796584e-09\n","W2:4.151778437056007e-09\n","b2:1.3987931122005915e-07\n"]}]},{"cell_type":"code","source":["# 오차역전파법을 사용한 학습 구현하기\n","\n","import sys, os\n","sys.path.append(os.pardir)\n","import numpy as np\n","from dataset.mnist import load_mnist\n","from two_layer_net import TwoLayerNet\n","\n","# 데이터 읽기\n","(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n","network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n","\n","iters_num = 10000\n","train_size = x_train.shape[0]\n","batch_size = 100\n","learning_rate = 0.1\n","\n","train_loss_list = []\n","train_acc_list = []\n","test_acc_list = []\n","\n","iter_per_epoch = max(train_size / batch_size, 1)\n","\n","for i in range(iters_num):\n","    batch_mask = np.random.choice(train_size, batch_size)\n","    x_batch = x_train[batch_mask]\n","    t_batch = t_train[batch_mask]\n","\n","    # 오차역전파법으로 기울기를 구한다. \n","    grad = network.gradient(x_batch, t_batch)\n","\n","    # 갱신\n","    for key in ('W1', 'b1', 'W2', 'b2'):\n","        network.params[key] -= learning_rate * grad[key]\n","\n","    loss = network.loss(x_batch, t_batch)\n","    train_loss_list.append(loss)\n","\n","    if i % iter_per_epoch == 0:\n","        train_acc = network.accuracy(x_train, t_train)\n","        test_acc = network.accuracy(x_test, t_test)\n","        train_acc_list.append(train_acc)\n","        test_acc_list.append(test_acc)\n","        print(train_acc, test_acc)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uHZvAhkXNMvN","executionInfo":{"status":"ok","timestamp":1658045930331,"user_tz":-540,"elapsed":154204,"user":{"displayName":"배재현","userId":"16111717144670092065"}},"outputId":"83147ffe-15a5-417a-ce2a-947bc3292e50"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["0.12138333333333333 0.1218\n","0.9067 0.9085\n","0.92265 0.9235\n","0.9368166666666666 0.9378\n","0.9450166666666666 0.945\n","0.9504 0.9486\n","0.9580666666666666 0.9562\n","0.9614166666666667 0.9582\n","0.9643833333333334 0.9597\n","0.9666333333333333 0.9632\n","0.9703833333333334 0.9644\n","0.9706333333333333 0.966\n","0.9730333333333333 0.9671\n","0.9747666666666667 0.9677\n","0.9766333333333334 0.9681\n","0.97755 0.9686\n","0.9790333333333333 0.9691\n"]}]}]}
